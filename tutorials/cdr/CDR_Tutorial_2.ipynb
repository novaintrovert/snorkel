{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chemical-Disease Relation (CDR) Tutorial\n",
    "\n",
    "In this example, we'll be writing an application to extract *mentions of* **chemical-induced-disease relationships** from Pubmed abstracts, as per the [BioCreative CDR Challenge](http://www.biocreative.org/resources/corpora/biocreative-v-cdr-corpus/).  This tutorial will show off some of the more advanced features of Snorkel, so we'll assume you've followed the Intro tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by reloading from the last notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from snorkel import SnorkelSession\n",
    "\n",
    "session = SnorkelSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.models import candidate_subclass\n",
    "\n",
    "ChemicalDisease = candidate_subclass('ChemicalDisease', ['chemical', 'disease'])\n",
    "\n",
    "train_cands = session.query(ChemicalDisease).filter(ChemicalDisease.split == 0).all()\n",
    "dev_cands = session.query(ChemicalDisease).filter(ChemicalDisease.split == 1).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part III: Writing LFs\n",
    "\n",
    "This tutorial features some more advanced LFs than the intro tutorial, with more focus on distant supervision and dependencies between LFs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distant supervision approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use the [Comparative Toxicogenomics Database](http://ctdbase.org/) (CTD) for distant supervision. The CTD lists chemical-condition entity pairs under three categories: therapy, marker, and unspecified. Therapy means the chemical treats the condition, marker means the chemical is typically present with the condition, and unspecified is...unspecified. We can write LFs based on these categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bz2\n",
    "from six.moves.cPickle import load\n",
    "\n",
    "with bz2.BZ2File('data/ctd.pkl.bz2', 'rb') as ctd_f:\n",
    "    ctd_unspecified, ctd_therapy, ctd_marker = load(ctd_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cand_in_ctd_unspecified(c):\n",
    "    return 1 if c.get_cids() in ctd_unspecified else 0\n",
    "\n",
    "def cand_in_ctd_therapy(c):\n",
    "    return 1 if c.get_cids() in ctd_therapy else 0\n",
    "\n",
    "def cand_in_ctd_marker(c):\n",
    "    return 1 if c.get_cids() in ctd_marker else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LF_in_ctd_unspecified(c):\n",
    "    return -1 * cand_in_ctd_unspecified(c)\n",
    "\n",
    "def LF_in_ctd_therapy(c):\n",
    "    return -1 * cand_in_ctd_therapy(c)\n",
    "\n",
    "def LF_in_ctd_marker(c):\n",
    "    return cand_in_ctd_marker(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text pattern approaches\n",
    "\n",
    "Now we'll use some LF helpers to create LFs based on indicative text patterns. We came up with these rules by using the viewer to examine training candidates and noting frequent patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from snorkel.lf_helpers import (\n",
    "    get_tagged_text,\n",
    "    rule_regex_search_tagged_text,\n",
    "    rule_regex_search_btw_AB,\n",
    "    rule_regex_search_btw_BA,\n",
    "    rule_regex_search_before_A,\n",
    "    rule_regex_search_before_B,\n",
    ")\n",
    "\n",
    "# List to parenthetical\n",
    "def ltp(x):\n",
    "    return '(' + '|'.join(x) + ')'\n",
    "\n",
    "def LF_induce(c):\n",
    "    return 1 if re.search(r'{{A}}.{0,20}induc.{0,20}{{B}}', get_tagged_text(c), flags=re.I) else 0\n",
    "\n",
    "causal_past = ['induced', 'caused', 'due']\n",
    "def LF_d_induced_by_c(c):\n",
    "    return rule_regex_search_btw_BA(c, '.{0,50}' + ltp(causal_past) + '.{0,9}(by|to).{0,50}', 1)\n",
    "def LF_d_induced_by_c_tight(c):\n",
    "    return rule_regex_search_btw_BA(c, '.{0,50}' + ltp(causal_past) + ' (by|to) ', 1)\n",
    "\n",
    "def LF_induce_name(c):\n",
    "    return 1 if 'induc' in c.chemical.get_span().lower() else 0     \n",
    "\n",
    "causal = ['cause[sd]?', 'induce[sd]?', 'associated with']\n",
    "def LF_c_cause_d(c):\n",
    "    return 1 if (\n",
    "        re.search(r'{{A}}.{0,50} ' + ltp(causal) + '.{0,50}{{B}}', get_tagged_text(c), re.I)\n",
    "        and not re.search('{{A}}.{0,50}(not|no).{0,20}' + ltp(causal) + '.{0,50}{{B}}', get_tagged_text(c), re.I)\n",
    "    ) else 0\n",
    "\n",
    "treat = ['treat', 'effective', 'prevent', 'resistant', 'slow', 'promise', 'therap']\n",
    "def LF_d_treat_c(c):\n",
    "    return rule_regex_search_btw_BA(c, '.{0,50}' + ltp(treat) + '.{0,50}', -1)\n",
    "def LF_c_treat_d(c):\n",
    "    return rule_regex_search_btw_AB(c, '.{0,50}' + ltp(treat) + '.{0,50}', -1)\n",
    "def LF_treat_d(c):\n",
    "    return rule_regex_search_before_B(c, ltp(treat) + '.{0,50}', -1)\n",
    "def LF_c_treat_d_wide(c):\n",
    "    return rule_regex_search_btw_AB(c, '.{0,200}' + ltp(treat) + '.{0,200}', -1)\n",
    "\n",
    "def LF_c_d(c):\n",
    "    return 1 if ('{{A}} {{B}}' in get_tagged_text(c)) else 0\n",
    "\n",
    "def LF_c_induced_d(c):\n",
    "    return 1 if (\n",
    "        ('{{A}} {{B}}' in get_tagged_text(c)) and \n",
    "        (('-induc' in c[0].get_span().lower()) or ('-assoc' in c[0].get_span().lower()))\n",
    "        ) else 0\n",
    "\n",
    "def LF_improve_before_disease(c):\n",
    "    return rule_regex_search_before_B(c, 'improv.*', -1)\n",
    "\n",
    "pat_terms = ['in a patient with ', 'in patients with']\n",
    "def LF_in_patient_with(c):\n",
    "    return -1 if re.search(ltp(pat_terms) + '{{B}}', get_tagged_text(c), flags=re.I) else 0\n",
    "\n",
    "uncertain = ['combin', 'possible', 'unlikely']\n",
    "def LF_uncertain(c):\n",
    "    return rule_regex_search_before_A(c, ltp(uncertain) + '.*', -1)\n",
    "\n",
    "def LF_induced_other(c):\n",
    "    return rule_regex_search_tagged_text(c, '{{A}}.{20,1000}-induced {{B}}', -1)\n",
    "\n",
    "def LF_far_c_d(c):\n",
    "    return rule_regex_search_btw_AB(c, '.{100,5000}', -1)\n",
    "\n",
    "def LF_far_d_c(c):\n",
    "    return rule_regex_search_btw_BA(c, '.{100,5000}', -1)\n",
    "\n",
    "def LF_risk_d(c):\n",
    "    return rule_regex_search_before_B(c, 'risk of ', 1)\n",
    "\n",
    "def LF_develop_d_following_c(c):\n",
    "    return 1 if re.search(r'develop.{0,25}{{B}}.{0,25}following.{0,25}{{A}}', get_tagged_text(c), flags=re.I) else 0\n",
    "\n",
    "procedure, following = ['inject', 'administrat'], ['following']\n",
    "def LF_d_following_c(c):\n",
    "    return 1 if re.search('{{B}}.{0,50}' + ltp(following) + '.{0,20}{{A}}.{0,50}' + ltp(procedure), get_tagged_text(c), flags=re.I) else 0\n",
    "\n",
    "def LF_measure(c):\n",
    "    return -1 if re.search('measur.{0,75}{{A}}', get_tagged_text(c), flags=re.I) else 0\n",
    "\n",
    "def LF_level(c):\n",
    "    return -1 if re.search('{{A}}.{0,25} level', get_tagged_text(c), flags=re.I) else 0\n",
    "\n",
    "def LF_neg_d(c):\n",
    "    return -1 if re.search('(none|not|no) .{0,25}{{B}}', get_tagged_text(c), flags=re.I) else 0\n",
    "\n",
    "WEAK_PHRASES = ['none', 'although', 'was carried out', 'was conducted',\n",
    "                'seems', 'suggests', 'risk', 'implicated',\n",
    "               'the aim', 'to (investigate|assess|study)']\n",
    "\n",
    "WEAK_RGX = r'|'.join(WEAK_PHRASES)\n",
    "\n",
    "def LF_weak_assertions(c):\n",
    "    return -1 if re.search(WEAK_RGX, get_tagged_text(c), flags=re.I) else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Composite LFs\n",
    "\n",
    "The following LFs take some of the strongest distant supervision and text pattern LFs, and combine them to form more specific LFs. These LFs introduce some obvious dependencies within the LF set, which we will model later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LF_ctd_marker_c_d(c):\n",
    "    return LF_c_d(c) * cand_in_ctd_marker(c)\n",
    "\n",
    "def LF_ctd_marker_induce(c):\n",
    "    return (LF_c_induced_d(c) or LF_d_induced_by_c_tight(c)) * cand_in_ctd_marker(c)\n",
    "\n",
    "def LF_ctd_therapy_treat(c):\n",
    "    return LF_c_treat_d_wide(c) * cand_in_ctd_therapy(c)\n",
    "\n",
    "def LF_ctd_unspecified_treat(c):\n",
    "    return LF_c_treat_d_wide(c) * cand_in_ctd_unspecified(c)\n",
    "\n",
    "def LF_ctd_unspecified_induce(c):\n",
    "    return (LF_c_induced_d(c) or LF_d_induced_by_c_tight(c)) * cand_in_ctd_unspecified(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rules based on context hierarchy\n",
    "\n",
    "These last two rules will make use of the context hierarchy. The first checks if there is a chemical mention much closer to the candidate's disease mention than the candidate's chemical mention. The second does the analog for diseases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LF_closer_chem(c):\n",
    "    # Get distance between chemical and disease\n",
    "    chem_start, chem_end = c.chemical.get_word_start(), c.chemical.get_word_end()\n",
    "    dis_start, dis_end = c.disease.get_word_start(), c.disease.get_word_end()\n",
    "    if dis_start < chem_start:\n",
    "        dist = chem_start - dis_end\n",
    "    else:\n",
    "        dist = dis_start - chem_end\n",
    "    # Try to find chemical closer than @dist/2 in either direction\n",
    "    sent = c.get_parent()\n",
    "    closest_other_chem = float('inf')\n",
    "    for i in range(dis_end, min(len(sent.words), dis_end + dist // 2)):\n",
    "        et, cid = sent.entity_types[i], sent.entity_cids[i]\n",
    "        if et == 'Chemical' and cid != sent.entity_cids[chem_start]:\n",
    "            return -1\n",
    "    for i in range(max(0, dis_start - dist // 2), dis_start):\n",
    "        et, cid = sent.entity_types[i], sent.entity_cids[i]\n",
    "        if et == 'Chemical' and cid != sent.entity_cids[chem_start]:\n",
    "            return -1\n",
    "    return 0\n",
    "\n",
    "def LF_closer_dis(c):\n",
    "    # Get distance between chemical and disease\n",
    "    chem_start, chem_end = c.chemical.get_word_start(), c.chemical.get_word_end()\n",
    "    dis_start, dis_end = c.disease.get_word_start(), c.disease.get_word_end()\n",
    "    if dis_start < chem_start:\n",
    "        dist = chem_start - dis_end\n",
    "    else:\n",
    "        dist = dis_start - chem_end\n",
    "    # Try to find chemical disease than @dist/8 in either direction\n",
    "    sent = c.get_parent()\n",
    "    for i in range(chem_end, min(len(sent.words), chem_end + dist // 8)):\n",
    "        et, cid = sent.entity_types[i], sent.entity_cids[i]\n",
    "        if et == 'Disease' and cid != sent.entity_cids[dis_start]:\n",
    "            return -1\n",
    "    for i in range(max(0, chem_start - dist // 8), chem_start):\n",
    "        et, cid = sent.entity_types[i], sent.entity_cids[i]\n",
    "        if et == 'Disease' and cid != sent.entity_cids[dis_start]:\n",
    "            return -1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LF_cand_in_ctd_marker_fixer(c):\n",
    "    sent.entity_cids[i]\n",
    "    \n",
    "    return cand_in_ctd_marker(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the LFs on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "LFs = [\n",
    "    LF_c_cause_d,\n",
    "    LF_c_d,\n",
    "    LF_c_induced_d,\n",
    "    LF_c_treat_d,\n",
    "    LF_c_treat_d_wide,\n",
    "    LF_closer_chem,\n",
    "    LF_closer_dis,\n",
    "    LF_ctd_marker_c_d,\n",
    "    LF_ctd_marker_induce,\n",
    "    LF_ctd_therapy_treat,\n",
    "    LF_ctd_unspecified_treat,\n",
    "    LF_ctd_unspecified_induce,\n",
    "    LF_d_following_c,\n",
    "    LF_d_induced_by_c,\n",
    "    LF_d_induced_by_c_tight,\n",
    "    LF_d_treat_c,\n",
    "    LF_develop_d_following_c,\n",
    "    LF_far_c_d,\n",
    "    LF_far_d_c,\n",
    "    LF_improve_before_disease,\n",
    "    LF_in_ctd_therapy,\n",
    "    LF_in_ctd_marker,\n",
    "    LF_in_patient_with,\n",
    "    LF_induce,\n",
    "    LF_induce_name,\n",
    "    LF_induced_other,\n",
    "    LF_level,\n",
    "    LF_measure,\n",
    "    LF_neg_d,\n",
    "    LF_risk_d,\n",
    "    LF_treat_d,\n",
    "    LF_uncertain,\n",
    "    LF_weak_assertions,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.annotations import LabelAnnotator\n",
    "labeler = LabelAnnotator(lfs=LFs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 7/8432 [00:00<02:11, 64.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8432/8432 [00:59<00:00, 142.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 56.1 s, sys: 1.11 s, total: 57.2 s\n",
      "Wall time: 59.7 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<8432x33 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 17440 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time L_train = labeler.apply(split=0)\n",
    "L_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LF_c_cause_d</th>\n",
       "      <td>0</td>\n",
       "      <td>0.031665</td>\n",
       "      <td>0.027989</td>\n",
       "      <td>0.012690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_c_d</th>\n",
       "      <td>1</td>\n",
       "      <td>0.021822</td>\n",
       "      <td>0.018264</td>\n",
       "      <td>0.005693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_c_induced_d</th>\n",
       "      <td>2</td>\n",
       "      <td>0.004151</td>\n",
       "      <td>0.004151</td>\n",
       "      <td>0.001898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_c_treat_d</th>\n",
       "      <td>3</td>\n",
       "      <td>0.047676</td>\n",
       "      <td>0.047676</td>\n",
       "      <td>0.019924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_c_treat_d_wide</th>\n",
       "      <td>4</td>\n",
       "      <td>0.088591</td>\n",
       "      <td>0.087524</td>\n",
       "      <td>0.037832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_closer_chem</th>\n",
       "      <td>5</td>\n",
       "      <td>0.187974</td>\n",
       "      <td>0.168999</td>\n",
       "      <td>0.091556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_closer_dis</th>\n",
       "      <td>6</td>\n",
       "      <td>0.014706</td>\n",
       "      <td>0.014231</td>\n",
       "      <td>0.009132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_ctd_marker_c_d</th>\n",
       "      <td>7</td>\n",
       "      <td>0.017789</td>\n",
       "      <td>0.017789</td>\n",
       "      <td>0.005337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_ctd_marker_induce</th>\n",
       "      <td>8</td>\n",
       "      <td>0.020398</td>\n",
       "      <td>0.020398</td>\n",
       "      <td>0.008065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_ctd_therapy_treat</th>\n",
       "      <td>9</td>\n",
       "      <td>0.047201</td>\n",
       "      <td>0.047201</td>\n",
       "      <td>0.017315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_ctd_unspecified_treat</th>\n",
       "      <td>10</td>\n",
       "      <td>0.057993</td>\n",
       "      <td>0.057993</td>\n",
       "      <td>0.028582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_ctd_unspecified_induce</th>\n",
       "      <td>11</td>\n",
       "      <td>0.016603</td>\n",
       "      <td>0.016603</td>\n",
       "      <td>0.007472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_d_following_c</th>\n",
       "      <td>12</td>\n",
       "      <td>0.000474</td>\n",
       "      <td>0.000474</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_d_induced_by_c</th>\n",
       "      <td>13</td>\n",
       "      <td>0.036409</td>\n",
       "      <td>0.033681</td>\n",
       "      <td>0.015062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_d_induced_by_c_tight</th>\n",
       "      <td>14</td>\n",
       "      <td>0.017552</td>\n",
       "      <td>0.017552</td>\n",
       "      <td>0.006286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_d_treat_c</th>\n",
       "      <td>15</td>\n",
       "      <td>0.027277</td>\n",
       "      <td>0.023838</td>\n",
       "      <td>0.014824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_develop_d_following_c</th>\n",
       "      <td>16</td>\n",
       "      <td>0.000830</td>\n",
       "      <td>0.000830</td>\n",
       "      <td>0.000474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_far_c_d</th>\n",
       "      <td>17</td>\n",
       "      <td>0.109820</td>\n",
       "      <td>0.096537</td>\n",
       "      <td>0.053605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_far_d_c</th>\n",
       "      <td>18</td>\n",
       "      <td>0.081594</td>\n",
       "      <td>0.070327</td>\n",
       "      <td>0.043643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_improve_before_disease</th>\n",
       "      <td>19</td>\n",
       "      <td>0.001542</td>\n",
       "      <td>0.001423</td>\n",
       "      <td>0.000712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_in_ctd_therapy</th>\n",
       "      <td>20</td>\n",
       "      <td>0.298743</td>\n",
       "      <td>0.257827</td>\n",
       "      <td>0.170659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_in_ctd_marker</th>\n",
       "      <td>21</td>\n",
       "      <td>0.611954</td>\n",
       "      <td>0.442244</td>\n",
       "      <td>0.347011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_in_patient_with</th>\n",
       "      <td>22</td>\n",
       "      <td>0.001542</td>\n",
       "      <td>0.000830</td>\n",
       "      <td>0.000474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_induce</th>\n",
       "      <td>23</td>\n",
       "      <td>0.089658</td>\n",
       "      <td>0.084203</td>\n",
       "      <td>0.030123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_induce_name</th>\n",
       "      <td>24</td>\n",
       "      <td>0.006523</td>\n",
       "      <td>0.006286</td>\n",
       "      <td>0.003439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_induced_other</th>\n",
       "      <td>25</td>\n",
       "      <td>0.040916</td>\n",
       "      <td>0.040204</td>\n",
       "      <td>0.019094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_level</th>\n",
       "      <td>26</td>\n",
       "      <td>0.006641</td>\n",
       "      <td>0.004981</td>\n",
       "      <td>0.002728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_measure</th>\n",
       "      <td>27</td>\n",
       "      <td>0.003676</td>\n",
       "      <td>0.002846</td>\n",
       "      <td>0.002491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_neg_d</th>\n",
       "      <td>28</td>\n",
       "      <td>0.018382</td>\n",
       "      <td>0.015299</td>\n",
       "      <td>0.011504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_risk_d</th>\n",
       "      <td>29</td>\n",
       "      <td>0.005337</td>\n",
       "      <td>0.005337</td>\n",
       "      <td>0.005337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_treat_d</th>\n",
       "      <td>30</td>\n",
       "      <td>0.022059</td>\n",
       "      <td>0.019687</td>\n",
       "      <td>0.011504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_uncertain</th>\n",
       "      <td>31</td>\n",
       "      <td>0.018264</td>\n",
       "      <td>0.016841</td>\n",
       "      <td>0.007590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_weak_assertions</th>\n",
       "      <td>32</td>\n",
       "      <td>0.112547</td>\n",
       "      <td>0.099146</td>\n",
       "      <td>0.069023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            j  Coverage  Overlaps  Conflicts\n",
       "LF_c_cause_d                0  0.031665  0.027989   0.012690\n",
       "LF_c_d                      1  0.021822  0.018264   0.005693\n",
       "LF_c_induced_d              2  0.004151  0.004151   0.001898\n",
       "LF_c_treat_d                3  0.047676  0.047676   0.019924\n",
       "LF_c_treat_d_wide           4  0.088591  0.087524   0.037832\n",
       "LF_closer_chem              5  0.187974  0.168999   0.091556\n",
       "LF_closer_dis               6  0.014706  0.014231   0.009132\n",
       "LF_ctd_marker_c_d           7  0.017789  0.017789   0.005337\n",
       "LF_ctd_marker_induce        8  0.020398  0.020398   0.008065\n",
       "LF_ctd_therapy_treat        9  0.047201  0.047201   0.017315\n",
       "LF_ctd_unspecified_treat   10  0.057993  0.057993   0.028582\n",
       "LF_ctd_unspecified_induce  11  0.016603  0.016603   0.007472\n",
       "LF_d_following_c           12  0.000474  0.000474   0.000000\n",
       "LF_d_induced_by_c          13  0.036409  0.033681   0.015062\n",
       "LF_d_induced_by_c_tight    14  0.017552  0.017552   0.006286\n",
       "LF_d_treat_c               15  0.027277  0.023838   0.014824\n",
       "LF_develop_d_following_c   16  0.000830  0.000830   0.000474\n",
       "LF_far_c_d                 17  0.109820  0.096537   0.053605\n",
       "LF_far_d_c                 18  0.081594  0.070327   0.043643\n",
       "LF_improve_before_disease  19  0.001542  0.001423   0.000712\n",
       "LF_in_ctd_therapy          20  0.298743  0.257827   0.170659\n",
       "LF_in_ctd_marker           21  0.611954  0.442244   0.347011\n",
       "LF_in_patient_with         22  0.001542  0.000830   0.000474\n",
       "LF_induce                  23  0.089658  0.084203   0.030123\n",
       "LF_induce_name             24  0.006523  0.006286   0.003439\n",
       "LF_induced_other           25  0.040916  0.040204   0.019094\n",
       "LF_level                   26  0.006641  0.004981   0.002728\n",
       "LF_measure                 27  0.003676  0.002846   0.002491\n",
       "LF_neg_d                   28  0.018382  0.015299   0.011504\n",
       "LF_risk_d                  29  0.005337  0.005337   0.005337\n",
       "LF_treat_d                 30  0.022059  0.019687   0.011504\n",
       "LF_uncertain               31  0.018264  0.016841   0.007590\n",
       "LF_weak_assertions         32  0.112547  0.099146   0.069023"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L_train.lf_stats(session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part IV: Training the generative model\n",
    "\n",
    "As mentioned above, we want to include the dependencies between our LFs when training the generative model. Snorkel makes it easy to do this! `DependencySelector` runs a fast structure learning algorithm over the matrix of LF outputs to identify a set of likely dependencies. We can see that these match up with our prior knowledge. For example, it identified a \"reinforcing\" dependency between `LF_c_induced_d` and `LF_ctd_marker_induce`. Recall that we constructed the latter using the former."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "247"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from snorkel.learning.structure import DependencySelector\n",
    "ds = DependencySelector()\n",
    "deps = ds.select(L_train, threshold=0.1)\n",
    "len(deps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll train the generative model, using the `deps` argument to account for the learned dependencies. We'll also model LF propensity here, unlike the intro tutorial. In addition to learning the accuracies of the LFs, this also learns their likelihood of labeling an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inferred cardinality: 2\n"
     ]
    }
   ],
   "source": [
    "from snorkel.learning import GenerativeModel\n",
    "\n",
    "gen_model = GenerativeModel(lf_propensity=True)\n",
    "gen_model.train(\n",
    "    L_train, deps=deps, decay=0.95, step_size=0.1/L_train.shape[0], reg_param=0.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_marginals = gen_model.marginals(L_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAD8CAYAAACRkhiPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAErVJREFUeJzt3X2sZHddx/H3x1bwiUq1F1L3wS1kS2wJLvamNjGYGhS2rbbFx90EabG6QFofibGoCQTTpD5gEyIWt7Jpa6S1UrGrLEKpaIPpCltZ+wSV27LSy27alSJgqtUuX/+Ys3bcvQ9zZ+bOXPb3fiWTe+Y3v3PO97dz737u+Z1z5qaqkCS16eumXYAkaXoMAUlqmCEgSQ0zBCSpYYaAJDXMEJCkhhkCktQwQ0CSGmYISFLDTp52Acs57bTTatOmTdMuQ5K+Ztx7773/VlUzg/Rd8yGwadMm9u3bN+0yJOlrRpJ/HbSv00GS1DBDQJIaZghIUsMMAUlq2LIhkGRXkieSPNDX9mdJ9nePA0n2d+2bkvxn32vv7lvnnCT3J5lL8s4kWZ0hSZIGNcjVQTcCfwDcfLShqn7q6HKSdwBf6uv/SFVtWWA71wM7gL3AHmAr8MGVlyxJGpdljwSq6m7gyYVe636b/0nglqW2keR04JSquqd6f8rsZuDSlZcrSRqnUc8JvAJ4vKo+09d2RpJPJvn7JK/o2tYB83195rs2SdIUjXqz2Hb+/1HAIWBjVX0hyTnAXyY5G1ho/n/RP26cZAe9qSM2btw4YomSpMUMHQJJTgZ+FDjnaFtVPQ083S3fm+QR4Ex6v/mv71t9PXBwsW1X1U5gJ8Ds7OyiYSGpDZuu/sBI6x+49qIxVXLiGWU66AeBT1fV/03zJJlJclK3/CJgM/BoVR0CvpLkvO48wuuAO0bYtyRpDAa5RPQW4B7gJUnmk1zRvbSN408Ifz9wX5J/Bt4HvLGqjp5UfhPwx8Ac8AheGSRJU7fsdFBVbV+k/fIF2m4Hbl+k/z7gpSusT5K0irxjWJIaZghIUsMMAUlqmCEgSQ0zBCSpYYaAJDXMEJCkhhkCktQwQ0CSGmYISFLDDAFJapghIEkNMwQkqWGGgCQ1zBCQpIYZApLUMENAkhpmCEhSwwwBSWqYISBJDTMEJKlhy4ZAkl1JnkjyQF/b25J8Psn+7nFh32tvSTKX5OEkr+5r39q1zSW5evxDkSSt1CBHAjcCWxdov66qtnSPPQBJzgK2AWd36/xhkpOSnAS8C7gAOAvY3vWVJE3Ryct1qKq7k2wacHuXALdW1dPAZ5PMAed2r81V1aMASW7t+j604oolSWMzyjmBq5Lc100Xndq1rQMe6+sz37Ut1i5JmqJhQ+B64MXAFuAQ8I6uPQv0rSXaF5RkR5J9SfYdPnx4yBIlScsZKgSq6vGqOlJVXwVu4Nkpn3lgQ1/X9cDBJdoX2/7OqpqtqtmZmZlhSpQkDWCoEEhyet/T1wBHrxzaDWxL8twkZwCbgY8DnwA2JzkjyXPonTzePXzZkqRxWPbEcJJbgPOB05LMA28Fzk+yhd6UzgHgDQBV9WCS2+id8H0GuLKqjnTbuQr4EHASsKuqHhz7aCRJKzLI1UHbF2h+zxL9rwGuWaB9D7BnRdVJklaVdwxLUsMMAUlqmCEgSQ0zBCSpYYaAJDXMEJCkhhkCktQwQ0CSGmYISFLDDAFJapghIEkNMwQkqWGGgCQ1zBCQpIYZApLUMENAkhpmCEhSwwwBSWqYISBJDTMEJKlhhoAkNWzZEEiyK8kTSR7oa/vdJJ9Ocl+S9yd5fte+Kcl/JtnfPd7dt845Se5PMpfknUmyOkOSJA1qkCOBG4Gtx7TdCby0ql4G/Avwlr7XHqmqLd3jjX3t1wM7gM3d49htSpImbNkQqKq7gSePaftwVT3TPd0LrF9qG0lOB06pqnuqqoCbgUuHK1mSNC7jOCfwM8AH+56fkeSTSf4+ySu6tnXAfF+f+a5tQUl2JNmXZN/hw4fHUKIkaSEjhUCS3wCeAf60azoEbKyqlwO/Arw3ySnAQvP/tdh2q2pnVc1W1ezMzMwoJUqSlnDysCsmuQz4YeCV3RQPVfU08HS3fG+SR4Az6f3m3z9ltB44OOy+JUnjMdSRQJKtwK8BF1fVU33tM0lO6pZfRO8E8KNVdQj4SpLzuquCXgfcMXL1kqSRLHskkOQW4HzgtCTzwFvpXQ30XODO7krPvd2VQN8PvD3JM8AR4I1VdfSk8pvoXWn0jfTOIfSfR5AkTcGyIVBV2xdofs8ifW8Hbl/ktX3AS1dUnSRpVXnHsCQ1zBCQpIYZApLUMENAkhpmCEhSwwwBSWqYISBJDTMEJKlhhoAkNcwQkKSGGQKS1DBDQJIaZghIUsMMAUlqmCEgSQ0zBCSpYYaAJDXMEJCkhhkCktQwQ0CSGjZQCCTZleSJJA/0tX1bkjuTfKb7emrXniTvTDKX5L4k39O3zmVd/88kuWz8w5EkrcSgRwI3AluPabsauKuqNgN3dc8BLgA2d48dwPXQCw3grcD3AucCbz0aHJKk6RgoBKrqbuDJY5ovAW7qlm8CLu1rv7l69gLPT3I68Grgzqp6sqq+CNzJ8cEiSZqgUc4JvLCqDgF0X1/Qta8DHuvrN9+1LdYuSZqSk1dhm1mgrZZoP34DyQ56U0ls3LhxfJVJY7Tp6g8Mve6Bay8aYyXS8EY5Eni8m+ah+/pE1z4PbOjrtx44uET7capqZ1XNVtXszMzMCCVKkpYySgjsBo5e4XMZcEdf++u6q4TOA77UTRd9CHhVklO7E8Kv6tokSVMy0HRQkluA84HTkszTu8rnWuC2JFcAnwN+ouu+B7gQmAOeAl4PUFVPJvkt4BNdv7dX1bEnmyVJEzRQCFTV9kVeeuUCfQu4cpHt7AJ2DVydJGlVecewJDXMEJCkhhkCktSw1bhPQNIa5v0N6ueRgCQ1zBCQpIYZApLUMENAkhpmCEhSwwwBSWqYISBJDTMEJKlhhoAkNcwQkKSGGQKS1DBDQJIaZghIUsMMAUlqmCEgSQ0zBCSpYYaAJDVs6BBI8pIk+/seX07yS0neluTzfe0X9q3zliRzSR5O8urxDEGSNKyh/7xkVT0MbAFIchLweeD9wOuB66rq9/r7JzkL2AacDXwH8JEkZ1bVkWFrkCSNZlzTQa8EHqmqf12izyXArVX1dFV9FpgDzh3T/iVJQxhXCGwDbul7flWS+5LsSnJq17YOeKyvz3zXJkmakpFDIMlzgIuBP++argdeTG+q6BDwjqNdF1i9FtnmjiT7kuw7fPjwqCVKkhYxjiOBC4B/qqrHAarq8ao6UlVfBW7g2SmfeWBD33rrgYMLbbCqdlbVbFXNzszMjKFESdJCxhEC2+mbCkpyet9rrwEe6JZ3A9uSPDfJGcBm4ONj2L8kaUhDXx0EkOSbgB8C3tDX/DtJttCb6jlw9LWqejDJbcBDwDPAlV4ZJEnTNVIIVNVTwLcf0/bTS/S/BrhmlH1KksbHO4YlqWGGgCQ1zBCQpIaNdE5AGodNV39gpPUPXHvRmCqR2uORgCQ1zBCQpIYZApLUMENAkhpmCEhSwwwBSWqYISBJDTMEJKlhhoAkNcwQkKSGGQKS1DBDQJIaZghIUsMMAUlqmCEgSQ0zBCSpYYaAJDVs5BBIciDJ/Un2J9nXtX1bkjuTfKb7emrXniTvTDKX5L4k3zPq/iVJwxvXkcAPVNWWqprtnl8N3FVVm4G7uucAFwCbu8cO4Pox7V+SNITVmg66BLipW74JuLSv/ebq2Qs8P8npq1SDJGkZ4/hD8wV8OEkBf1RVO4EXVtUhgKo6lOQFXd91wGN96853bYf6N5hkB70jBTZu3DiGEiVpOJuu/sDQ6x649qIxVrI6xhEC31dVB7v/6O9M8ukl+maBtjquoRckOwFmZ2ePe12SNB4jTwdV1cHu6xPA+4FzgcePTvN0X5/ous8DG/pWXw8cHLUGSdJwRgqBJN+c5HlHl4FXAQ8Au4HLum6XAXd0y7uB13VXCZ0HfOnotJEkafJGnQ56IfD+JEe39d6q+psknwBuS3IF8DngJ7r+e4ALgTngKeD1I+5fkjSCkUKgqh4FvnuB9i8Ar1ygvYArR9mnJGl8vGNYkhpmCEhSwwwBSWqYISBJDTMEJKlh47hjWPqaNcpHAkgnAkNA0kQYuGuT00GS1DBDQJIa5nSQpIE5pXPi8UhAkhrmkYC+5vnbqTQ8Q0DSCc9fFBbndJAkNcwjAf2fE/1vqa4l/ltrrfBIQJIaZghIUsMMAUlqmCEgSQ0zBCSpYUOHQJINST6a5FNJHkzyi13725J8Psn+7nFh3zpvSTKX5OEkrx7HACRJwxvlEtFngDdX1T8leR5wb5I7u9euq6rf6++c5CxgG3A28B3AR5KcWVVHRqhBkjSCoUOgqg4Bh7rlryT5FLBuiVUuAW6tqqeBzyaZA84F7hm2Bh3POyMlrcRYzgkk2QS8HPjHrumqJPcl2ZXk1K5tHfBY32rzLB0akqRVNnIIJPkW4Hbgl6rqy8D1wIuBLfSOFN5xtOsCq9ci29yRZF+SfYcPHx61REnSIkYKgSRfTy8A/rSq/gKgqh6vqiNV9VXgBnpTPtD7zX9D3+rrgYMLbbeqdlbVbFXNzszMjFKiJGkJo1wdFOA9wKeq6vf72k/v6/Ya4IFueTewLclzk5wBbAY+Puz+JUmjG+XqoO8Dfhq4P8n+ru3Xge1JttCb6jkAvAGgqh5MchvwEL0ri670yiBJmq5Rrg76GAvP8+9ZYp1rgGuG3afWLq9Kmhz/rTVO3jEsSQ0zBCSpYYaAJDXMEJCkhhkCktQwQ0CSGmYISFLDDAFJapghIEkNMwQkqWGjfHaQVoEfCSBpkjwSkKSGGQKS1DBDQJIaZghIUsMMAUlqmCEgSQ3zElFJWiWjXPJ94NqLxljJ4jwSkKSGGQKS1DCngxbhnbuSWjDxI4EkW5M8nGQuydWT3r8k6VkTDYEkJwHvAi4AzgK2JzlrkjVIkp416SOBc4G5qnq0qv4buBW4ZMI1SJI6kz4nsA54rO/5PPC9q7Uz5/UlaWmTDoEs0FbHdUp2ADu6p/+R5OFVrWpxpwH/NqV9j8uJMAY4McbhGNaONT+O/PayXZYaw3cOup9Jh8A8sKHv+Xrg4LGdqmonsHNSRS0myb6qmp12HaM4EcYAJ8Y4HMPacSKMY1xjmPQ5gU8Am5OckeQ5wDZg94RrkCR1JnokUFXPJLkK+BBwErCrqh6cZA2SpGdN/GaxqtoD7Jn0foc09SmpMTgRxgAnxjgcw9pxIoxjLGNI1XHnZSVJjfCzgySpYYYAy3+URZJfSfJQkvuS3JVk4MuvJmWAMbwxyf1J9if52Fq8U3vQjxRJ8uNJKsmavLpjgPfi8iSHu/dif5KfnUadSxnkvUjyk93PxYNJ3jvpGpczwPtwXd978C9J/n0adS5ngHFsTPLRJJ/s/o+6cEU7qKqmH/ROUD8CvAh4DvDPwFnH9PkB4Ju65TcBfzbtuocYwyl9yxcDfzPtulc6hq7f84C7gb3A7LTrHvK9uBz4g2nXOuIYNgOfBE7tnr9g2nUP8/3U1//n6V2oMvXah3gvdgJv6pbPAg6sZB8eCQzwURZV9dGqeqp7upfe/Q1rySBj+HLf029mgZv0pmzQjxT5LeB3gP+aZHErcCJ8NMogY/g54F1V9UWAqnpiwjUuZ6Xvw3bglolUtjKDjKOAU7rlb2WBe6+WYggs/FEW65bofwXwwVWtaOUGGkOSK5M8Qu8/0V+YUG2DWnYMSV4ObKiqv55kYSs06PfTj3WH7u9LsmGB16dpkDGcCZyZ5B+S7E2ydWLVDWbgn+tuevcM4G8nUNdKDTKOtwGvTTJP78rLn1/JDgyBAT/KAiDJa4FZ4HdXtaKVG2gMVfWuqnox8GvAb656VSuz5BiSfB1wHfDmiVU0nEHei78CNlXVy4CPADetelUrM8gYTqY3JXQ+vd+i/zjJ81e5rpUY+Oea3k2r76uqI6tYz7AGGcd24MaqWg9cCPxJ9/MyEENgwI+ySPKDwG8AF1fV0xOqbVADjaHPrcClq1rRyi03hucBLwX+LskB4Dxg9xo8Obzse1FVX+j7HroBOGdCtQ1qkO+neeCOqvqfqvos8DC9UFgrVvIzsY21ORUEg43jCuA2gKq6B/gGep8rNJhpn/iY9oPebzSP0jscPHri5exj+ryc3smZzdOud4QxbO5b/hFg37TrXukYjun/d6zNE8ODvBen9y2/Btg77bqHGMNW4KZu+TR6UxbfPu3aV/r9BLwEOEB3z9Raewz4XnwQuLxb/i56ITHweJr/85K1yEdZJHk7vf8od9Ob/vkW4M+TAHyuqi6eWtHHGHAMV3VHM/8DfBG4bHoVH2/AMax5A47jF5JcDDwDPEnvaqE1Y8AxfAh4VZKHgCPAr1bVF6ZX9f+3gu+n7cCt1f0PutYMOI43Azck+WV6U0WXr2Q83jEsSQ3znIAkNcwQkKSGGQKS1DBDQJIaZghIUsMMAUlqmCEgSQ0zBCSpYf8LFLf/VM4FMwcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(train_marginals, bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vincentchen/code/snorkel/snorkel/learning/gen_learning.py:350: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \"Precision\": tp / (tp + fp),\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>0.002208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.413793</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.001204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.493056</td>\n",
       "      <td>0.0144</td>\n",
       "      <td>0.492063</td>\n",
       "      <td>0.006222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.559184</td>\n",
       "      <td>0.0245</td>\n",
       "      <td>0.559633</td>\n",
       "      <td>0.012244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.594949</td>\n",
       "      <td>0.0990</td>\n",
       "      <td>0.609756</td>\n",
       "      <td>0.060217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.592593</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.002007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.605263</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.002007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.553846</td>\n",
       "      <td>0.0130</td>\n",
       "      <td>0.557377</td>\n",
       "      <td>0.006825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.450704</td>\n",
       "      <td>0.0213</td>\n",
       "      <td>0.457944</td>\n",
       "      <td>0.009835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.0060</td>\n",
       "      <td>0.617647</td>\n",
       "      <td>0.004215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.475000</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.001405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.001807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.568627</td>\n",
       "      <td>0.0102</td>\n",
       "      <td>0.511111</td>\n",
       "      <td>0.004617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.593354</td>\n",
       "      <td>0.1896</td>\n",
       "      <td>0.601686</td>\n",
       "      <td>0.114613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.668542</td>\n",
       "      <td>0.6221</td>\n",
       "      <td>0.665694</td>\n",
       "      <td>0.412084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.609467</td>\n",
       "      <td>0.0169</td>\n",
       "      <td>0.580645</td>\n",
       "      <td>0.010839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.475000</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.001405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.000803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.0018</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.552381</td>\n",
       "      <td>0.0210</td>\n",
       "      <td>0.603960</td>\n",
       "      <td>0.012244</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Accuracy  Coverage  Precision    Recall\n",
       "0   0.428571    0.0049   0.440000  0.002208\n",
       "1   0.413793    0.0029   0.428571  0.001204\n",
       "2   0.800000    0.0005   0.666667  0.000401\n",
       "3   0.493056    0.0144   0.492063  0.006222\n",
       "4   0.559184    0.0245   0.559633  0.012244\n",
       "5   0.594949    0.0990   0.609756  0.060217\n",
       "6   0.444444    0.0009   0.500000  0.000401\n",
       "7   0.592593    0.0027   0.666667  0.002007\n",
       "8   0.605263    0.0038   0.588235  0.002007\n",
       "9   0.553846    0.0130   0.557377  0.006825\n",
       "10  0.450704    0.0213   0.457944  0.009835\n",
       "11  0.200000    0.0010   0.250000  0.000201\n",
       "12  0.000000    0.0001        NaN  0.000000\n",
       "13  0.533333    0.0060   0.617647  0.004215\n",
       "14  0.409091    0.0022   0.500000  0.000803\n",
       "15  0.475000    0.0040   0.411765  0.001405\n",
       "16  0.000000    0.0003   0.000000  0.000000\n",
       "17  0.541667    0.0024   0.750000  0.001807\n",
       "18  0.568627    0.0102   0.511111  0.004617\n",
       "19  1.000000    0.0002   1.000000  0.000401\n",
       "20  0.593354    0.1896   0.601686  0.114613\n",
       "21  0.668542    0.6221   0.665694  0.412084\n",
       "22  0.000000    0.0002   0.000000  0.000000\n",
       "23  0.609467    0.0169   0.580645  0.010839\n",
       "24  0.222222    0.0009   0.250000  0.000201\n",
       "25  0.475000    0.0040   0.388889  0.001405\n",
       "26  0.500000    0.0002   0.500000  0.000201\n",
       "27  0.500000    0.0004   0.500000  0.000201\n",
       "28  0.473684    0.0019   0.333333  0.000602\n",
       "29  0.600000    0.0010   0.571429  0.000803\n",
       "30  0.277778    0.0018   0.250000  0.000602\n",
       "31  0.500000    0.0006   0.500000  0.000201\n",
       "32  0.552381    0.0210   0.603960  0.012244"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_model.learned_lf_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vincentchen/code/snorkel/snorkel/learning/gen_learning.py:350: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \"Precision\": tp / (tp + fp),\n",
      "/Users/vincentchen/code/snorkel/snorkel/learning/gen_learning.py:352: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \"Accuracy\": (tp + tn) / coverage,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0     0.542857\n",
       "1     0.441176\n",
       "2     0.428571\n",
       "3     0.492187\n",
       "4     0.575472\n",
       "5     0.587229\n",
       "6     0.222222\n",
       "7     0.526316\n",
       "8     0.500000\n",
       "9     0.544118\n",
       "10    0.522523\n",
       "11    0.576923\n",
       "12         NaN\n",
       "13    0.580247\n",
       "14    0.380952\n",
       "15    0.441176\n",
       "16    0.000000\n",
       "17    0.625000\n",
       "18    0.600000\n",
       "19         NaN\n",
       "20    0.602139\n",
       "21    0.680953\n",
       "22    0.500000\n",
       "23    0.639706\n",
       "24    0.600000\n",
       "25    0.473684\n",
       "26    0.666667\n",
       "27    0.333333\n",
       "28    0.578947\n",
       "29    0.333333\n",
       "30    0.500000\n",
       "31    0.600000\n",
       "32    0.580508\n",
       "Name: Accuracy, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_model.learned_lf_stats()['Accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 8432 marginals\n"
     ]
    }
   ],
   "source": [
    "from snorkel.annotations import save_marginals\n",
    "save_marginals(session, L_train, train_marginals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking performance against development set labels\n",
    "\n",
    "Finally, we'll run the labeler on the development set, load in some external labels, then evaluate the LF performance. The external labels are applied via a small script for convenience. It maps the document-level relation annotations found in the CDR file to mention-level labels. Note that these will not be perfect, although they are pretty good. If we wanted to keep iterating, we could use `snorkel.lf_helpers.test_LF` against the dev set, or look at some false positive and false negative candidates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnnotatorLabels created: 0\n"
     ]
    }
   ],
   "source": [
    "from load_external_annotations import load_external_labels\n",
    "load_external_labels(session, ChemicalDisease, split=1, annotator='gold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<920x1 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 920 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from snorkel.annotations import load_gold_labels\n",
    "L_gold_dev = load_gold_labels(session, annotator_name='gold', split=1)\n",
    "L_gold_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 5/920 [00:00<00:20, 44.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 920/920 [00:10<00:00, 90.84it/s] \n"
     ]
    }
   ],
   "source": [
    "L_dev = labeler.apply_existing(split=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Scores (Un-adjusted)\n",
      "========================================\n",
      "Pos. class accuracy: 0.892\n",
      "Neg. class accuracy: 0.617\n",
      "Precision            0.537\n",
      "Recall               0.892\n",
      "F1                   0.671\n",
      "----------------------------------------\n",
      "TP: 273 | FP: 235 | TN: 379 | FN: 33\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_ = gen_model.error_analysis(session, L_dev, L_gold_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vincentchen/code/snorkel/snorkel/learning/gen_learning.py:350: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \"Precision\": tp / (tp + fp),\n",
      "/Users/vincentchen/code/snorkel/snorkel/annotations.py:137: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ac = (tp+tn) / (tp+tn+fp+fn)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>TN</th>\n",
       "      <th>Empirical Acc.</th>\n",
       "      <th>Learned Acc.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LF_c_cause_d</th>\n",
       "      <td>0</td>\n",
       "      <td>0.034783</td>\n",
       "      <td>0.033696</td>\n",
       "      <td>0.011957</td>\n",
       "      <td>22</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.604651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_c_d</th>\n",
       "      <td>1</td>\n",
       "      <td>0.020652</td>\n",
       "      <td>0.018478</td>\n",
       "      <td>0.003261</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.693878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_c_induced_d</th>\n",
       "      <td>2</td>\n",
       "      <td>0.002174</td>\n",
       "      <td>0.002174</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_c_treat_d</th>\n",
       "      <td>3</td>\n",
       "      <td>0.031522</td>\n",
       "      <td>0.031522</td>\n",
       "      <td>0.017391</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>0.689655</td>\n",
       "      <td>0.586466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_c_treat_d_wide</th>\n",
       "      <td>4</td>\n",
       "      <td>0.077174</td>\n",
       "      <td>0.076087</td>\n",
       "      <td>0.042391</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>54</td>\n",
       "      <td>0.760563</td>\n",
       "      <td>0.546218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_closer_chem</th>\n",
       "      <td>5</td>\n",
       "      <td>0.205435</td>\n",
       "      <td>0.191304</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>134</td>\n",
       "      <td>0.708995</td>\n",
       "      <td>0.620332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_closer_dis</th>\n",
       "      <td>6</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.006522</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_ctd_marker_c_d</th>\n",
       "      <td>7</td>\n",
       "      <td>0.018478</td>\n",
       "      <td>0.018478</td>\n",
       "      <td>0.003261</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.458333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_ctd_marker_induce</th>\n",
       "      <td>8</td>\n",
       "      <td>0.018478</td>\n",
       "      <td>0.018478</td>\n",
       "      <td>0.006522</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.593750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_ctd_therapy_treat</th>\n",
       "      <td>9</td>\n",
       "      <td>0.041304</td>\n",
       "      <td>0.041304</td>\n",
       "      <td>0.027174</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>30</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.567073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_ctd_unspecified_treat</th>\n",
       "      <td>10</td>\n",
       "      <td>0.057609</td>\n",
       "      <td>0.057609</td>\n",
       "      <td>0.033696</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>37</td>\n",
       "      <td>0.698113</td>\n",
       "      <td>0.577889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_ctd_unspecified_induce</th>\n",
       "      <td>11</td>\n",
       "      <td>0.015217</td>\n",
       "      <td>0.015217</td>\n",
       "      <td>0.004348</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.545455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_d_following_c</th>\n",
       "      <td>12</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_d_induced_by_c</th>\n",
       "      <td>13</td>\n",
       "      <td>0.035870</td>\n",
       "      <td>0.035870</td>\n",
       "      <td>0.017391</td>\n",
       "      <td>24</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.433735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_d_induced_by_c_tight</th>\n",
       "      <td>14</td>\n",
       "      <td>0.017391</td>\n",
       "      <td>0.017391</td>\n",
       "      <td>0.006522</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.347826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_d_treat_c</th>\n",
       "      <td>15</td>\n",
       "      <td>0.044565</td>\n",
       "      <td>0.036957</td>\n",
       "      <td>0.027174</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>25</td>\n",
       "      <td>0.609756</td>\n",
       "      <td>0.621622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_develop_d_following_c</th>\n",
       "      <td>16</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_far_c_d</th>\n",
       "      <td>17</td>\n",
       "      <td>0.143478</td>\n",
       "      <td>0.129348</td>\n",
       "      <td>0.082609</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>103</td>\n",
       "      <td>0.780303</td>\n",
       "      <td>0.545455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_far_d_c</th>\n",
       "      <td>18</td>\n",
       "      <td>0.095652</td>\n",
       "      <td>0.085870</td>\n",
       "      <td>0.056522</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>57</td>\n",
       "      <td>0.647727</td>\n",
       "      <td>0.609091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_improve_before_disease</th>\n",
       "      <td>19</td>\n",
       "      <td>0.007609</td>\n",
       "      <td>0.007609</td>\n",
       "      <td>0.004348</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_in_ctd_therapy</th>\n",
       "      <td>20</td>\n",
       "      <td>0.316304</td>\n",
       "      <td>0.271739</td>\n",
       "      <td>0.207609</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "      <td>197</td>\n",
       "      <td>0.676976</td>\n",
       "      <td>0.609795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_in_ctd_marker</th>\n",
       "      <td>21</td>\n",
       "      <td>0.606522</td>\n",
       "      <td>0.479348</td>\n",
       "      <td>0.380435</td>\n",
       "      <td>304</td>\n",
       "      <td>254</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.544803</td>\n",
       "      <td>0.681268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_in_patient_with</th>\n",
       "      <td>22</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_induce</th>\n",
       "      <td>23</td>\n",
       "      <td>0.091304</td>\n",
       "      <td>0.085870</td>\n",
       "      <td>0.031522</td>\n",
       "      <td>57</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.638710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_induce_name</th>\n",
       "      <td>24</td>\n",
       "      <td>0.003261</td>\n",
       "      <td>0.003261</td>\n",
       "      <td>0.001087</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_induced_other</th>\n",
       "      <td>25</td>\n",
       "      <td>0.033696</td>\n",
       "      <td>0.033696</td>\n",
       "      <td>0.016304</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.562500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_level</th>\n",
       "      <td>26</td>\n",
       "      <td>0.019565</td>\n",
       "      <td>0.015217</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_measure</th>\n",
       "      <td>27</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_neg_d</th>\n",
       "      <td>28</td>\n",
       "      <td>0.008696</td>\n",
       "      <td>0.007609</td>\n",
       "      <td>0.003261</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_risk_d</th>\n",
       "      <td>29</td>\n",
       "      <td>0.001087</td>\n",
       "      <td>0.001087</td>\n",
       "      <td>0.001087</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_treat_d</th>\n",
       "      <td>30</td>\n",
       "      <td>0.013043</td>\n",
       "      <td>0.013043</td>\n",
       "      <td>0.003261</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.541667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_uncertain</th>\n",
       "      <td>31</td>\n",
       "      <td>0.027174</td>\n",
       "      <td>0.026087</td>\n",
       "      <td>0.015217</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_weak_assertions</th>\n",
       "      <td>32</td>\n",
       "      <td>0.113043</td>\n",
       "      <td>0.096739</td>\n",
       "      <td>0.057609</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>70</td>\n",
       "      <td>0.673077</td>\n",
       "      <td>0.632035</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            j  Coverage  Overlaps  Conflicts   TP   FP  FN  \\\n",
       "LF_c_cause_d                0  0.034783  0.033696   0.011957   22   10   0   \n",
       "LF_c_d                      1  0.020652  0.018478   0.003261   11    8   0   \n",
       "LF_c_induced_d              2  0.002174  0.002174   0.000000    1    1   0   \n",
       "LF_c_treat_d                3  0.031522  0.031522   0.017391    0    0   9   \n",
       "LF_c_treat_d_wide           4  0.077174  0.076087   0.042391    0    0  17   \n",
       "LF_closer_chem              5  0.205435  0.191304   0.125000    0    0  55   \n",
       "LF_closer_dis               6  0.010870  0.010870   0.006522    0    0   2   \n",
       "LF_ctd_marker_c_d           7  0.018478  0.018478   0.003261   11    6   0   \n",
       "LF_ctd_marker_induce        8  0.018478  0.018478   0.006522   12    5   0   \n",
       "LF_ctd_therapy_treat        9  0.041304  0.041304   0.027174    0    0   8   \n",
       "LF_ctd_unspecified_treat   10  0.057609  0.057609   0.033696    0    0  16   \n",
       "LF_ctd_unspecified_induce  11  0.015217  0.015217   0.004348   10    4   0   \n",
       "LF_d_following_c           12  0.000000  0.000000   0.000000    0    0   0   \n",
       "LF_d_induced_by_c          13  0.035870  0.035870   0.017391   24    9   0   \n",
       "LF_d_induced_by_c_tight    14  0.017391  0.017391   0.006522   11    5   0   \n",
       "LF_d_treat_c               15  0.044565  0.036957   0.027174    0    0  16   \n",
       "LF_develop_d_following_c   16  0.000000  0.000000   0.000000    0    0   0   \n",
       "LF_far_c_d                 17  0.143478  0.129348   0.082609    0    0  29   \n",
       "LF_far_d_c                 18  0.095652  0.085870   0.056522    0    0  31   \n",
       "LF_improve_before_disease  19  0.007609  0.007609   0.004348    0    0   1   \n",
       "LF_in_ctd_therapy          20  0.316304  0.271739   0.207609    0    0  94   \n",
       "LF_in_ctd_marker           21  0.606522  0.479348   0.380435  304  254   0   \n",
       "LF_in_patient_with         22  0.000000  0.000000   0.000000    0    0   0   \n",
       "LF_induce                  23  0.091304  0.085870   0.031522   57   27   0   \n",
       "LF_induce_name             24  0.003261  0.003261   0.001087    1    2   0   \n",
       "LF_induced_other           25  0.033696  0.033696   0.016304    0    0   3   \n",
       "LF_level                   26  0.019565  0.015217   0.010870    0    0   6   \n",
       "LF_measure                 27  0.000000  0.000000   0.000000    0    0   0   \n",
       "LF_neg_d                   28  0.008696  0.007609   0.003261    0    0   2   \n",
       "LF_risk_d                  29  0.001087  0.001087   0.001087    1    0   0   \n",
       "LF_treat_d                 30  0.013043  0.013043   0.003261    0    0   1   \n",
       "LF_uncertain               31  0.027174  0.026087   0.015217    0    0   2   \n",
       "LF_weak_assertions         32  0.113043  0.096739   0.057609    0    0  34   \n",
       "\n",
       "                            TN  Empirical Acc.  Learned Acc.  \n",
       "LF_c_cause_d                 0        0.687500      0.604651  \n",
       "LF_c_d                       0        0.578947      0.693878  \n",
       "LF_c_induced_d               0        0.500000      0.333333  \n",
       "LF_c_treat_d                20        0.689655      0.586466  \n",
       "LF_c_treat_d_wide           54        0.760563      0.546218  \n",
       "LF_closer_chem             134        0.708995      0.620332  \n",
       "LF_closer_dis                8        0.800000      0.555556  \n",
       "LF_ctd_marker_c_d            0        0.647059      0.458333  \n",
       "LF_ctd_marker_induce         0        0.705882      0.593750  \n",
       "LF_ctd_therapy_treat        30        0.789474      0.567073  \n",
       "LF_ctd_unspecified_treat    37        0.698113      0.577889  \n",
       "LF_ctd_unspecified_induce    0        0.714286      0.545455  \n",
       "LF_d_following_c             0             NaN      0.000000  \n",
       "LF_d_induced_by_c            0        0.727273      0.433735  \n",
       "LF_d_induced_by_c_tight      0        0.687500      0.347826  \n",
       "LF_d_treat_c                25        0.609756      0.621622  \n",
       "LF_develop_d_following_c     0             NaN      0.000000  \n",
       "LF_far_c_d                 103        0.780303      0.545455  \n",
       "LF_far_d_c                  57        0.647727      0.609091  \n",
       "LF_improve_before_disease    6        0.857143      0.500000  \n",
       "LF_in_ctd_therapy          197        0.676976      0.609795  \n",
       "LF_in_ctd_marker             0        0.544803      0.681268  \n",
       "LF_in_patient_with           0             NaN      0.500000  \n",
       "LF_induce                    0        0.678571      0.638710  \n",
       "LF_induce_name               0        0.333333      0.600000  \n",
       "LF_induced_other            28        0.903226      0.562500  \n",
       "LF_level                    12        0.666667      0.200000  \n",
       "LF_measure                   0             NaN      0.666667  \n",
       "LF_neg_d                     6        0.750000      0.600000  \n",
       "LF_risk_d                    0        1.000000      0.500000  \n",
       "LF_treat_d                  11        0.916667      0.541667  \n",
       "LF_uncertain                23        0.920000      0.500000  \n",
       "LF_weak_assertions          70        0.673077      0.632035  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L_dev.lf_stats(session, L_gold_dev, gen_model.learned_lf_stats()['Accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vincentchen/code/snorkel/snorkel/annotations.py:137: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ac = (tp+tn) / (tp+tn+fp+fn)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>TN</th>\n",
       "      <th>Empirical Acc.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LF_c_cause_d</th>\n",
       "      <td>0</td>\n",
       "      <td>0.031665</td>\n",
       "      <td>0.027989</td>\n",
       "      <td>0.012690</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_c_d</th>\n",
       "      <td>1</td>\n",
       "      <td>0.021822</td>\n",
       "      <td>0.018264</td>\n",
       "      <td>0.005693</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_c_induced_d</th>\n",
       "      <td>2</td>\n",
       "      <td>0.004151</td>\n",
       "      <td>0.004151</td>\n",
       "      <td>0.001898</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_c_treat_d</th>\n",
       "      <td>3</td>\n",
       "      <td>0.047676</td>\n",
       "      <td>0.047676</td>\n",
       "      <td>0.019924</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_c_treat_d_wide</th>\n",
       "      <td>4</td>\n",
       "      <td>0.088591</td>\n",
       "      <td>0.087524</td>\n",
       "      <td>0.037832</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_closer_chem</th>\n",
       "      <td>5</td>\n",
       "      <td>0.187974</td>\n",
       "      <td>0.168999</td>\n",
       "      <td>0.091556</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_closer_dis</th>\n",
       "      <td>6</td>\n",
       "      <td>0.014706</td>\n",
       "      <td>0.014231</td>\n",
       "      <td>0.009132</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_ctd_marker_c_d</th>\n",
       "      <td>7</td>\n",
       "      <td>0.017789</td>\n",
       "      <td>0.017789</td>\n",
       "      <td>0.005337</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_ctd_marker_induce</th>\n",
       "      <td>8</td>\n",
       "      <td>0.020398</td>\n",
       "      <td>0.020398</td>\n",
       "      <td>0.008065</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_ctd_therapy_treat</th>\n",
       "      <td>9</td>\n",
       "      <td>0.047201</td>\n",
       "      <td>0.047201</td>\n",
       "      <td>0.017315</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_ctd_unspecified_treat</th>\n",
       "      <td>10</td>\n",
       "      <td>0.057993</td>\n",
       "      <td>0.057993</td>\n",
       "      <td>0.028582</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_ctd_unspecified_induce</th>\n",
       "      <td>11</td>\n",
       "      <td>0.016603</td>\n",
       "      <td>0.016603</td>\n",
       "      <td>0.007472</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_d_following_c</th>\n",
       "      <td>12</td>\n",
       "      <td>0.000474</td>\n",
       "      <td>0.000474</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_d_induced_by_c</th>\n",
       "      <td>13</td>\n",
       "      <td>0.036409</td>\n",
       "      <td>0.033681</td>\n",
       "      <td>0.015062</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_d_induced_by_c_tight</th>\n",
       "      <td>14</td>\n",
       "      <td>0.017552</td>\n",
       "      <td>0.017552</td>\n",
       "      <td>0.006286</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_d_treat_c</th>\n",
       "      <td>15</td>\n",
       "      <td>0.027277</td>\n",
       "      <td>0.023838</td>\n",
       "      <td>0.014824</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_develop_d_following_c</th>\n",
       "      <td>16</td>\n",
       "      <td>0.000830</td>\n",
       "      <td>0.000830</td>\n",
       "      <td>0.000474</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_far_c_d</th>\n",
       "      <td>17</td>\n",
       "      <td>0.109820</td>\n",
       "      <td>0.096537</td>\n",
       "      <td>0.053605</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_far_d_c</th>\n",
       "      <td>18</td>\n",
       "      <td>0.081594</td>\n",
       "      <td>0.070327</td>\n",
       "      <td>0.043643</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_improve_before_disease</th>\n",
       "      <td>19</td>\n",
       "      <td>0.001542</td>\n",
       "      <td>0.001423</td>\n",
       "      <td>0.000712</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_in_ctd_therapy</th>\n",
       "      <td>20</td>\n",
       "      <td>0.298743</td>\n",
       "      <td>0.257827</td>\n",
       "      <td>0.170659</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_in_ctd_marker</th>\n",
       "      <td>21</td>\n",
       "      <td>0.611954</td>\n",
       "      <td>0.442244</td>\n",
       "      <td>0.347011</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_in_patient_with</th>\n",
       "      <td>22</td>\n",
       "      <td>0.001542</td>\n",
       "      <td>0.000830</td>\n",
       "      <td>0.000474</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_induce</th>\n",
       "      <td>23</td>\n",
       "      <td>0.089658</td>\n",
       "      <td>0.084203</td>\n",
       "      <td>0.030123</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_induce_name</th>\n",
       "      <td>24</td>\n",
       "      <td>0.006523</td>\n",
       "      <td>0.006286</td>\n",
       "      <td>0.003439</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_induced_other</th>\n",
       "      <td>25</td>\n",
       "      <td>0.040916</td>\n",
       "      <td>0.040204</td>\n",
       "      <td>0.019094</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_level</th>\n",
       "      <td>26</td>\n",
       "      <td>0.006641</td>\n",
       "      <td>0.004981</td>\n",
       "      <td>0.002728</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_measure</th>\n",
       "      <td>27</td>\n",
       "      <td>0.003676</td>\n",
       "      <td>0.002846</td>\n",
       "      <td>0.002491</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_neg_d</th>\n",
       "      <td>28</td>\n",
       "      <td>0.018382</td>\n",
       "      <td>0.015299</td>\n",
       "      <td>0.011504</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_risk_d</th>\n",
       "      <td>29</td>\n",
       "      <td>0.005337</td>\n",
       "      <td>0.005337</td>\n",
       "      <td>0.005337</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_treat_d</th>\n",
       "      <td>30</td>\n",
       "      <td>0.022059</td>\n",
       "      <td>0.019687</td>\n",
       "      <td>0.011504</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_uncertain</th>\n",
       "      <td>31</td>\n",
       "      <td>0.018264</td>\n",
       "      <td>0.016841</td>\n",
       "      <td>0.007590</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_weak_assertions</th>\n",
       "      <td>32</td>\n",
       "      <td>0.112547</td>\n",
       "      <td>0.099146</td>\n",
       "      <td>0.069023</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            j  Coverage  Overlaps  Conflicts  TP  FP  FN  TN  \\\n",
       "LF_c_cause_d                0  0.031665  0.027989   0.012690   0   0   0   0   \n",
       "LF_c_d                      1  0.021822  0.018264   0.005693   0   0   0   0   \n",
       "LF_c_induced_d              2  0.004151  0.004151   0.001898   0   0   0   0   \n",
       "LF_c_treat_d                3  0.047676  0.047676   0.019924   0   0   0   0   \n",
       "LF_c_treat_d_wide           4  0.088591  0.087524   0.037832   0   0   0   0   \n",
       "LF_closer_chem              5  0.187974  0.168999   0.091556   0   0   0   0   \n",
       "LF_closer_dis               6  0.014706  0.014231   0.009132   0   0   0   0   \n",
       "LF_ctd_marker_c_d           7  0.017789  0.017789   0.005337   0   0   0   0   \n",
       "LF_ctd_marker_induce        8  0.020398  0.020398   0.008065   0   0   0   0   \n",
       "LF_ctd_therapy_treat        9  0.047201  0.047201   0.017315   0   0   0   0   \n",
       "LF_ctd_unspecified_treat   10  0.057993  0.057993   0.028582   0   0   0   0   \n",
       "LF_ctd_unspecified_induce  11  0.016603  0.016603   0.007472   0   0   0   0   \n",
       "LF_d_following_c           12  0.000474  0.000474   0.000000   0   0   0   0   \n",
       "LF_d_induced_by_c          13  0.036409  0.033681   0.015062   0   0   0   0   \n",
       "LF_d_induced_by_c_tight    14  0.017552  0.017552   0.006286   0   0   0   0   \n",
       "LF_d_treat_c               15  0.027277  0.023838   0.014824   0   0   0   0   \n",
       "LF_develop_d_following_c   16  0.000830  0.000830   0.000474   0   0   0   0   \n",
       "LF_far_c_d                 17  0.109820  0.096537   0.053605   0   0   0   0   \n",
       "LF_far_d_c                 18  0.081594  0.070327   0.043643   0   0   0   0   \n",
       "LF_improve_before_disease  19  0.001542  0.001423   0.000712   0   0   0   0   \n",
       "LF_in_ctd_therapy          20  0.298743  0.257827   0.170659   0   0   0   0   \n",
       "LF_in_ctd_marker           21  0.611954  0.442244   0.347011   0   0   0   0   \n",
       "LF_in_patient_with         22  0.001542  0.000830   0.000474   0   0   0   0   \n",
       "LF_induce                  23  0.089658  0.084203   0.030123   0   0   0   0   \n",
       "LF_induce_name             24  0.006523  0.006286   0.003439   0   0   0   0   \n",
       "LF_induced_other           25  0.040916  0.040204   0.019094   0   0   0   0   \n",
       "LF_level                   26  0.006641  0.004981   0.002728   0   0   0   0   \n",
       "LF_measure                 27  0.003676  0.002846   0.002491   0   0   0   0   \n",
       "LF_neg_d                   28  0.018382  0.015299   0.011504   0   0   0   0   \n",
       "LF_risk_d                  29  0.005337  0.005337   0.005337   0   0   0   0   \n",
       "LF_treat_d                 30  0.022059  0.019687   0.011504   0   0   0   0   \n",
       "LF_uncertain               31  0.018264  0.016841   0.007590   0   0   0   0   \n",
       "LF_weak_assertions         32  0.112547  0.099146   0.069023   0   0   0   0   \n",
       "\n",
       "                           Empirical Acc.  \n",
       "LF_c_cause_d                          NaN  \n",
       "LF_c_d                                NaN  \n",
       "LF_c_induced_d                        NaN  \n",
       "LF_c_treat_d                          NaN  \n",
       "LF_c_treat_d_wide                     NaN  \n",
       "LF_closer_chem                        NaN  \n",
       "LF_closer_dis                         NaN  \n",
       "LF_ctd_marker_c_d                     NaN  \n",
       "LF_ctd_marker_induce                  NaN  \n",
       "LF_ctd_therapy_treat                  NaN  \n",
       "LF_ctd_unspecified_treat              NaN  \n",
       "LF_ctd_unspecified_induce             NaN  \n",
       "LF_d_following_c                      NaN  \n",
       "LF_d_induced_by_c                     NaN  \n",
       "LF_d_induced_by_c_tight               NaN  \n",
       "LF_d_treat_c                          NaN  \n",
       "LF_develop_d_following_c              NaN  \n",
       "LF_far_c_d                            NaN  \n",
       "LF_far_d_c                            NaN  \n",
       "LF_improve_before_disease             NaN  \n",
       "LF_in_ctd_therapy                     NaN  \n",
       "LF_in_ctd_marker                      NaN  \n",
       "LF_in_patient_with                    NaN  \n",
       "LF_induce                             NaN  \n",
       "LF_induce_name                        NaN  \n",
       "LF_induced_other                      NaN  \n",
       "LF_level                              NaN  \n",
       "LF_measure                            NaN  \n",
       "LF_neg_d                              NaN  \n",
       "LF_risk_d                             NaN  \n",
       "LF_treat_d                            NaN  \n",
       "LF_uncertain                          NaN  \n",
       "LF_weak_assertions                    NaN  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L_gold_train = load_gold_labels(session, annotator_name='gold', split=0)\n",
    "L_train.lf_stats(session, L_gold_train, gen_model.learned_lf_stats()['Accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# show failed examples for a given LF\n",
    "\n",
    "# LF_labels = L_dev[:, 21].toarray() # LF_in_ctd_marker\n",
    "# gt = L_gold_dev.toarray()\n",
    "\n",
    "# failed_idx = np.where(np.logical_and(LF_labels !=  gt, LF_labels != 0))[0] \n",
    "# print (len(failed_idx))\n",
    "# for idx in failed_idx:\n",
    "#     cand = dev_cands[idx]\n",
    "#     print (cand)\n",
    "#     print (cand.get_parent())\n",
    "#     print ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slicing..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_marginals = gen_model.marginals(L_dev)\n",
    "test_marginals = gen_model.marginals(L_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- LF_c_cause_d (150 labeled, Cov: 0.0321) --- \n",
      "\u001b[32mLF: 0.5400, Gen: 0.0000, Disc: 0.0000\u001b[0m\n",
      "--- LF_c_d (105 labeled, Cov: 0.0224) --- \n",
      "\u001b[32mLF: 0.4762, Gen: 0.0000, Disc: 0.0000\u001b[0m\n",
      "--- LF_c_induced_d (12 labeled, Cov: 0.0026) --- \n",
      "\u001b[32mLF: 0.8333, Gen: 0.0000, Disc: 0.0000\u001b[0m\n",
      "--- LF_c_treat_d (252 labeled, Cov: 0.0539) --- \n",
      "\u001b[32mLF: 0.8770, Gen: 0.0000, Disc: 0.0000\u001b[0m\n",
      "--- LF_c_treat_d_wide (471 labeled, Cov: 0.1007) --- \n",
      "\u001b[32mLF: 0.8471, Gen: 0.0000, Disc: 0.0000\u001b[0m\n",
      "--- LF_closer_chem (803 labeled, Cov: 0.1717) --- \n",
      "\u001b[32mLF: 0.8680, Gen: 0.0000, Disc: 0.0000\u001b[0m\n",
      "--- LF_closer_dis (57 labeled, Cov: 0.0122) --- \n",
      "\u001b[32mLF: 0.7895, Gen: 0.0000, Disc: 0.0000\u001b[0m\n",
      "--- LF_ctd_marker_c_d (84 labeled, Cov: 0.0180) --- \n",
      "\u001b[32mLF: 0.5952, Gen: 0.0000, Disc: 0.0000\u001b[0m\n",
      "--- LF_ctd_marker_induce (100 labeled, Cov: 0.0214) --- \n",
      "\u001b[32mLF: 0.7700, Gen: 0.0000, Disc: 0.0000\u001b[0m\n",
      "--- LF_ctd_therapy_treat (261 labeled, Cov: 0.0558) --- \n",
      "\u001b[32mLF: 0.9234, Gen: 0.0000, Disc: 0.0000\u001b[0m\n",
      "--- LF_ctd_unspecified_treat (308 labeled, Cov: 0.0658) --- \n",
      "\u001b[32mLF: 0.8377, Gen: 0.0000, Disc: 0.0000\u001b[0m\n",
      "--- LF_ctd_unspecified_induce (84 labeled, Cov: 0.0180) --- \n",
      "\u001b[32mLF: 0.7857, Gen: 0.0000, Disc: 0.0000\u001b[0m\n",
      "--- LF_d_following_c (2 labeled, Cov: 0.0004) --- \n",
      "\u001b[32mLF: 1.0000, Gen: 0.0000, Disc: 0.0000\u001b[0m\n",
      "--- LF_d_induced_by_c (177 labeled, Cov: 0.0378) --- \n",
      "\u001b[32mLF: 0.6158, Gen: 0.0000, Disc: 0.0000\u001b[0m\n",
      "--- LF_d_induced_by_c_tight (97 labeled, Cov: 0.0207) --- \n",
      "\u001b[32mLF: 0.6907, Gen: 0.0000, Disc: 0.0000\u001b[0m\n",
      "--- LF_d_treat_c (163 labeled, Cov: 0.0348) --- \n",
      "\u001b[32mLF: 0.7117, Gen: 0.0000, Disc: 0.0000\u001b[0m\n",
      "--- LF_develop_d_following_c (4 labeled, Cov: 0.0009) --- \n",
      "\u001b[32mLF: 1.0000, Gen: 0.0000, Disc: 0.0000\u001b[0m\n",
      "--- LF_far_c_d (547 labeled, Cov: 0.1169) --- \n",
      "\u001b[32mLF: 0.7697, Gen: 0.0000, Disc: 0.0000\u001b[0m\n",
      "--- LF_far_d_c (338 labeled, Cov: 0.0723) --- \n",
      "\u001b[32mLF: 0.7249, Gen: 0.0000, Disc: 0.0000\u001b[0m\n",
      "--- LF_improve_before_disease (10 labeled, Cov: 0.0021) --- \n",
      "\u001b[32mLF: 0.7000, Gen: 0.0000, Disc: 0.0000\u001b[0m\n",
      "--- LF_in_ctd_therapy (1398 labeled, Cov: 0.2988) --- \n",
      "\u001b[32mLF: 0.7847, Gen: 0.0000, Disc: 0.0000\u001b[0m\n",
      "--- LF_in_ctd_marker (2665 labeled, Cov: 0.5697) --- \n",
      "\u001b[32mLF: 0.5557, Gen: 0.0000, Disc: 0.0000\u001b[0m\n",
      "--- LF_in_patient_with (9 labeled, Cov: 0.0019) --- \n",
      "\u001b[32mLF: 0.8889, Gen: 0.0000, Disc: 0.0000\u001b[0m\n",
      "--- LF_induce (391 labeled, Cov: 0.0836) --- \n",
      "\u001b[32mLF: 0.6803, Gen: 0.0000, Disc: 0.0000\u001b[0m\n",
      "--- LF_induce_name (20 labeled, Cov: 0.0043) --- \n",
      "\u001b[32mLF: 0.5000, Gen: 0.0000, Disc: 0.0000\u001b[0m\n",
      "--- LF_induced_other (181 labeled, Cov: 0.0387) --- \n",
      "\u001b[32mLF: 0.7624, Gen: 0.0000, Disc: 0.0000\u001b[0m\n",
      "--- LF_level (35 labeled, Cov: 0.0075) --- \n",
      "\u001b[32mLF: 0.8000, Gen: 0.0000, Disc: 0.0000\u001b[0m\n",
      "--- LF_measure (11 labeled, Cov: 0.0024) --- \n",
      "\u001b[32mLF: 0.8182, Gen: 0.0000, Disc: 0.0000\u001b[0m\n",
      "--- LF_neg_d (54 labeled, Cov: 0.0115) --- \n",
      "\u001b[32mLF: 0.7778, Gen: 0.0000, Disc: 0.0000\u001b[0m\n",
      "--- LF_risk_d (14 labeled, Cov: 0.0030) --- \n",
      "\u001b[32mLF: 0.3571, Gen: 0.0000, Disc: 0.0000\u001b[0m\n",
      "--- LF_treat_d (115 labeled, Cov: 0.0246) --- \n",
      "\u001b[32mLF: 0.7565, Gen: 0.0000, Disc: 0.0000\u001b[0m\n",
      "--- LF_uncertain (87 labeled, Cov: 0.0186) --- \n",
      "\u001b[32mLF: 0.7356, Gen: 0.0000, Disc: 0.0000\u001b[0m\n",
      "--- LF_weak_assertions (458 labeled, Cov: 0.0979) --- \n",
      "\u001b[32mLF: 0.6703, Gen: 0.0000, Disc: 0.0000\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from termcolor import colored\n",
    "def lf_vs_gen_vs_disc(L, L_fns, gt, gen_labels, disc_labels, show_examples=False, sorted=False):\n",
    "    \"\"\" Computes metrics comparing labeling functions, generative model, and discriminative model.\n",
    "    \n",
    "    Note: shows in 'red' text LFs for which LFs preform better than the disc. model.\n",
    "    \"\"\"\n",
    "    \n",
    "    results = {}\n",
    "    for lf_label, lf in zip(L, L_fns):\n",
    "        \n",
    "        # LF correct but generative model wrong\n",
    "        lf_over_gen = np.logical_and(gen_labels != gt, lf_label == gt)\n",
    "        num_lf_over_gen = np.sum(lf_over_gen)\n",
    "\n",
    "        # compute num correct when the LF has assigned a label in {-1, 1}\n",
    "        not_abstained_idx = np.where(lf_label != 0)[0]\n",
    "        num_labeled_by_lf = len(not_abstained_idx) # denominator\n",
    "        \n",
    "        lf_correct = np.sum((lf_label == gt)[not_abstained_idx])\n",
    "        gen_correct = np.sum((gen_labels == gt)[not_abstained_idx])\n",
    "        disc_correct = np.sum((gen_labels == gt)[not_abstained_idx])\n",
    "        \n",
    "\n",
    "#         if (num_labeled_by_lf > 0) :\n",
    "        results[lf.__name__]= {\n",
    "            'idx': not_abstained_idx,\n",
    "            'lf_label': lf_label,\n",
    "            'num_labeled_by_lf': num_labeled_by_lf,\n",
    "            'lf_over_gen_score': num_lf_over_gen / num_labeled_by_lf,\n",
    "            'lf_score': lf_correct / num_labeled_by_lf,\n",
    "            'gen_score': gen_correct / num_labeled_by_lf,\n",
    "            'disc_score': disc_correct / num_labeled_by_lf\n",
    "        }\n",
    "\n",
    "    # pring overall scores\n",
    "    if sorted:\n",
    "        # by score diff\n",
    "        sorted_dict = sorted(results.items(), key=lambda kv: kv[1]['lf_score'] - kv[1]['gen_score'], reverse=True)\n",
    "        # by LF score\n",
    "#         sorted_dict = sorted(results.items(), key=lambda kv: kv[1]['lf_score'], reverse=True)\n",
    "        # by coverage\n",
    "#         sorted_dict = sorted(results.items(), key=lambda kv: kv[1]['num_labeled_by_lf']/len(gt), reverse=True)\n",
    "    else:\n",
    "        sorted_dict = results.items()\n",
    "\n",
    "    for k,v in sorted_dict:\n",
    "        \n",
    "        # find experts\n",
    "#         if v['num_labeled_by_lf']/len(gt) > 0.1:\n",
    "#             continue\n",
    "        \n",
    "#         if v['lf_score'] < 0.8: # acc\n",
    "#             continue\n",
    "\n",
    "        print ('--- %s (%d labeled, Cov: %.4f) --- ' % (k,v['num_labeled_by_lf'], v['num_labeled_by_lf']/len(gt)))\n",
    "        to_print = 'LF: %.4f, Gen: %.4f, Disc: %.4f' % (v['lf_score'], v['gen_score'], v['disc_score'])\n",
    "        if v['lf_score'] > v['gen_score']:\n",
    "            print(colored(to_print, 'green'))\n",
    "        else:\n",
    "            print (to_print)\n",
    "        \n",
    "        if show_examples:\n",
    "            for idx in v['idx']:\n",
    "                c = dev_cands[idx]\n",
    "                sent = c.get_parent()\n",
    "                print ('GT:', gt[idx], 'LF:', v['lf_label'][idx], 'Gen:', gen_labels[idx])\n",
    "                print (c )\n",
    "                print (sent)\n",
    "                print ('-')\n",
    "\n",
    "    return sorted_dict\n",
    "    \n",
    "# # convert marginals to hard labels\n",
    "# comparison = lf_vs_gen_vs_disc(\n",
    "#     L=L_dev.toarray().T, \n",
    "#     L_fns=LFs,\n",
    "#     gt=np.squeeze(L_gold_dev.toarray()),\n",
    "#     gen_labels=2 * (dev_marginals > 0.5) - 1,\n",
    "#     disc_labels=np.load('lstm_preds.npy')\n",
    "# )\n",
    "\n",
    "L_gold_test = load_gold_labels(session, annotator_name='gold', split=2)\n",
    "comparison = lf_vs_gen_vs_disc(\n",
    "    L=L_test.toarray().T, \n",
    "    L_fns=LFs,\n",
    "    gt=np.squeeze(L_gold_test.toarray()),\n",
    "#     gen_labels=2 * (dev_marginals > 0.5) - 1,\n",
    "    gen_labels=np.zeros((L_gold_test.toarray()).shape), # HACK -- no scores\n",
    "    disc_labels=np.load('lstm_preds.npy')\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 9/4678 [00:00<00:58, 79.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4678/4678 [00:53<00:00, 88.24it/s] \n"
     ]
    }
   ],
   "source": [
    "# we need this to see slice coverage on the test set\n",
    "L_test = labeler.apply_existing(split=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dev_marginals' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-a1148aa26108>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mL_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mL_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtrain_marginals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_marginals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mdev_marginals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdev_marginals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0maccs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearned_lf_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dev_marginals' is not defined"
     ]
    }
   ],
   "source": [
    "np.savez('snorkel_data.npz', \n",
    "    L_train=L_train.toarray(), \n",
    "    L_dev=L_dev.toarray(),\n",
    "    L_test=L_test.toarray(),\n",
    "    train_marginals=train_marginals,\n",
    "    dev_marginals=dev_marginals,\n",
    "    accs=np.array(gen_model.learned_lf_stats()['Accuracy'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
